{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e67b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install GroundingDINO\n",
    "!git clone https://github.com/IDEA-Research/GroundingDINO.git /content/GroundingDINO\n",
    "%cd /content/GroundingDINO\n",
    "!pip install -e .\n",
    "%cd /content\n",
    "\n",
    "# Install Segment Anything\n",
    "!git clone https://github.com/facebookresearch/segment-anything.git /content/segment-anything\n",
    "%cd /content/segment-anything\n",
    "!pip install -e .\n",
    "%cd /content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd537e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch, cv2, numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from groundingdino.util.inference import load_model, predict\n",
    "from groundingdino.util import box_ops\n",
    "from segment_anything import sam_model_registry, SamPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08971132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Grounding DINO\n",
    "gd_config = \"/content/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "gd_ckpt = \"/content/weights/groundingdino_swint_ogc.pth\"\n",
    "gd_model = load_model(gd_config, gd_ckpt).eval()\n",
    "\n",
    "# Load SAM\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"/content/weights/sam_vit_h.pth\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sam.to(device)\n",
    "sam_pred = SamPredictor(sam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa00736",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read image\n",
    "image_path = \"/content/your_image.jpg\"  # Change this to your image path\n",
    "img = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "H, W, _ = img.shape\n",
    "\n",
    "# Detect with prompt\n",
    "PROMPT = \"helmet on person\"\n",
    "boxes, logits, phrases = predict(gd_model, img, caption=PROMPT, box_threshold=0.35, text_threshold=0.25)\n",
    "xyxy = box_ops.xywh_to_xyxy(boxes) * torch.tensor([W, H, W, H])\n",
    "xyxy = xyxy.cpu().numpy().astype(int)\n",
    "\n",
    "# Separate person and helmet boxes\n",
    "person_boxes = [b for b, p in zip(xyxy, phrases) if \"person\" in p]\n",
    "helmet_boxes = [b for b, p in zip(xyxy, phrases) if \"helmet\" in p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c6839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(img)\n",
    "\n",
    "helmeted = 0\n",
    "nohelmet = 0\n",
    "\n",
    "for pbox in person_boxes:\n",
    "    x1, y1, x2, y2 = pbox\n",
    "    sam_pred.set_image(img)\n",
    "    masks, scores, _ = sam_pred.predict(box=np.array([pbox]), multimask_output=False)\n",
    "    mask = masks[0]\n",
    "\n",
    "    # Check overlap with any helmet box\n",
    "    overlaps = 0\n",
    "    for hbox in helmet_boxes:\n",
    "        hx1, hy1, hx2, hy2 = hbox\n",
    "        helmet_mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "        helmet_mask[hy1:hy2, hx1:hx2] = 1\n",
    "        if np.logical_and(mask, helmet_mask).sum() > 0:\n",
    "            overlaps += 1\n",
    "\n",
    "    if overlaps:\n",
    "        helmeted += 1\n",
    "        color = \"green\"\n",
    "    else:\n",
    "        nohelmet += 1\n",
    "        color = \"red\"\n",
    "\n",
    "    ax.add_patch(patches.Rectangle((x1, y1), x2 - x1, y2 - y1, edgecolor=color, linewidth=3, fill=False))\n",
    "\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(f\"👷 Total people: {len(person_boxes)}\")\n",
    "print(f\"🪖 Wearing helmets: {helmeted}\")\n",
    "print(f\"🙍 Without helmets: {nohelmet}\")\n",
    "print(f\"🪖 Helmet present? {'Yes' if helmeted>0 else 'No'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
